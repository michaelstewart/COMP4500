package parseDependencies;

import java.io.IOException;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;

import dependencies.DependSet;
import dependencies.Primitive;
import dependencies.Program;
import dependencies.Statement;
import source.ErrorHandler;
import source.Errors;
import source.Position;
import source.Severity;
import source.Source;

/**
 * class Parser - recursive descent parser for Simple programming language. 
 *
 *  The syntax analyzer recognises a Simple program according to the following
 *  syntax specification using a recursive descent parser. It constructs
 *  the corresponding abstract syntax tree and skeleton symbol table.
 *  EBNF Grammar:
 *  Program -> InputVariables Statement END_OF_FILE
 *  InputVariables -> KW_INPUTS Variables SEMICOLON
 *  Variables -> IDENTIFIER { COMMA IDENTIFIER } 
 *  Statement -> NullStatement | Assignment |  
 *               CompoundStatement | Select | Repeat
 *  NullStatement -> KW_NULL SEMICOLON
 *  Assignment -> IDENTIFIER ASSIGN Expression SEMICOLON
 *  Expression -> NUMBER | Variables
 *  CompoundStatement -> LCURLY Statement { Statement } RCURLY
 *  Select -> KW_SELECT LCURLY Statement { ALT Statement } RCURLY
 *  Repeat -> KW_REPEAT Statement
 *
 *  where any constructs not defined by the above productions
 *  are terminal symbols generated by the lexical analyser.
 */
public class Parser {

    /******************************* Constants *****************************/
    /* Starting sets for various parsing rules */
    /** Set of tokens that can start a Statement */
    private final static TokenSet STATEMENT_START_SET =
        new TokenSet( Token.KW_NULL, Token.IDENTIFIER, 
                Token.LCURLY, Token.KW_SELECT, Token.KW_REPEAT );
    private final static TokenSet EXPRESSION_START_SET =
            new TokenSet( Token.NUMBER, Token.IDENTIFIER );
    
    /*************************** Instance Variables ************************/
    /** The lexical analyzer */
    private Scanner lex;
    /** Control verbose parser debugging output */
    private boolean debugParse;
    /** The current token */
    private LexicalToken token;
    /** Source file handler for the program to be parsed */
    private Source source;
    /** The object to report errors to */
    private Errors errors = ErrorHandler.getErrorHandler();
    /** Track nesting depth in parsing rules */
    private int debugLevel = 0;
    
    /****************************** Constructor ****************************/
    /** Construct a parser with the given lexer 
     * @param lex - Scanner object for performing lexical analysis
     * @param debugParse - generate parser debugging output if true 
     * @requires lex != null;
     */
    public Parser( Scanner lex, boolean debugParse ) throws IOException {
        this.lex = lex;
        this.debugParse = debugParse;
        token = lex.getNextToken();      /* Initialise with first token */
        source = lex.getSourceHandler();
    }
    /***************************** Public Method ****************************/
    /** Parse the input stream. 
     *  @return constructed tree only if the stream was parsed correctly.
     */
    public Program parse() {
        Program program = parseProgram( new TokenSet( Token.END_OF_FILE ) );
        if( errors.hadErrors() ) {
            program = null;
        }
        errors.flush();
        return program;
    }

    /**************************** Support Methods ***************************/
    /** Get the next token and place it in the variable token. 
     * Declare a fatal error on IOException
     * @requires token != Token.EOF;
     */
    private void nextToken() {
        try {
            token = lex.getNextToken();
        } catch( IOException e ) {
            errors.errorMessage( "Caught IOException " + e, Severity.FATAL,
                                Position.NO_POSITION );
            /* Never returns, but just in case: */
            System.exit(1);
        }
    }
    /** Match if token is known to be expected, otherwise there is an error in
     * the parser. This version used to move on to the next token and give 
     * debugging output if enabled. 
     * @param expected - token expected next in the input stream.
     */
    private void match( Token expected ) {
        parseAssert( token.isMatch( expected ), 
                "Match assertion failed on " + expected );
        debugMessage( "Matched " + tokenString( token ) );
        nextToken();
    }
    /** Match a token equal to that expected.
     * If the current token is the expected token, it is skipped,
     * otherwise an error is reported and error recovery attempted.
     * For the error recovery, if the current token can follow the expected
     * token, then it is assumed that the expected token was omitted and
     * no error recovery is necessary, otherwise the current token is skipped.
     * If the current token is skipped then the next token may be the
     * expected token, if so, it is matched.
     * @param expected - token expected next in the input stream.
     * @param follows - set of tokens expected to follow the expected token.
     * @requires follows is nonempty
     */
    private void match( Token expected, TokenSet follows ) {
        if( token.isMatch( expected ) ) {
            match( expected );
        } else {
            parseError( "Parse error, expecting '" + expected + "'" );
            /* If the current token may follow the expected token then
             * treat it as though the expected token was missing and
             * do no further error recovery.
             */ 
            if( !token.isIn(follows) && !token.isMatch(Token.END_OF_FILE) ) {
                // Skip the erroneous token
                debugMessage( "Skipping " + tokenString( token ) );
                nextToken();
                /* If after skipping, the (new) token is not the expected 
                 * token we do no further error recovery (in match at least).
                 */
                if( token.isMatch( expected ) ) {
                    /* If after skipping the erroneous token we find 
                     * the expected token we match it
                     */
                    match( expected );
                }
            }
        }
    }
    /** Match when follow set is a single token
     * @param expected - token expected next in the input stream.
     * @param follows - single token that may follow
     */
    private void match( Token expected, Token follows ) {
        match( expected, new TokenSet( follows ) );
    }
    /** Return token name and position as debug string */
    private String tokenString( LexicalToken token ) {
        return "'" + token.toString() + "'" + 
            " at line " + source.getLineNumber( token.getPosn() ) +
            " column " + source.offset( token.getPosn() );
    }
    /** Skip tokens until one is found which is in the parameter set find. 
     * Used for error recovery. 
     * @param find - set of tokens: skip until one found in this set
     * @requires find.contains( Token.EOF ); 
     */
    private void skipTo( TokenSet find ) {
        while( ! token.isIn( find ) ) {
            debugMessage( "Skipping " + tokenString( token ) );
            nextToken();
        }
    }
    /** Begin a parsing rule. 
     * Ensure that the next token is in the set of tokens expected 
     * at the start of a grammar rule. 
     * An error is reported if it isn't.
     * @param rule - name of the rule for use in error messages
     * @param expected - set of tokens expected at start of rule
     * @param recoverSet - set of tokens to recover at on a syntax error
     * @return true iff an expected token was (eventually) found.
     */
    private boolean beginRule( String rule, TokenSet expected,
            TokenSet recoverSet ) {
        debugMessage( "Begin parse " + rule + " recover on " + recoverSet );
        debugLevel++;
        if( ! token.isIn( expected ) ) {
            parseError( token + " cannot start " + rule );
            skipTo( recoverSet.union( expected ) );
            if( !token.isIn( expected ) ) {
                debugLevel--; /* Decrease as this beginRule failed */
                return false;
            }
        }
        return true;
    }
    /** Begin a parsing rule. 
     * Same as above, except that expected is a single token.
     * @param rule - name of the rule for use in error messages
     * @param expected - token expected at start of rule
     * @param recoverSet set of tokens to recover at on a syntax error
     * @return true iff an expected token was (eventually) found.
     */
    private boolean beginRule( String rule, Token expected,
            TokenSet recoverSet) {
        return beginRule( rule, new TokenSet( expected ), recoverSet );
    }
    /** Version of beginRule when failure indicates that there
     * is an error in the parser.
     * @param rule - name of the rule for use in error messages
     * @param expected - set of tokens expected at start of rule
     */
    private void beginRule( String rule, TokenSet expected ) {
        debugMessage( "Begin parse " + rule );
        debugLevel++;
        if( ! token.isIn( expected ) ) {
            fatal( token + " cannot start " + rule );
            // doesn't return from fatal error
        }
    }
    /** Version of beginRule when failure indicates that there
     * is an error in the parser.
     * Same as above, except that expected is a single token.
     * @param rule - name of the rule for use in error messages
     * @param - expected token expected at start of rule
     */
    private void beginRule( String rule, Token expected ) {
        beginRule( rule, new TokenSet( expected ) );
    }
    /** End a parsing rule.
     * Ensure that the current token is a member of the recovery set 
     * (i.e., something which an ancestor rule is expecting).
     * @param rule name of the rule for use in error messages
     * @param recoverSet set of tokens to recover at on a syntax error
     * @requires recoverSet.contains( Token.EOF);
     */
    private void endRule( String rule, TokenSet recoverSet ) {
        if( ! token.isIn( recoverSet ) ) {
            parseError( token + " cannot follow " + rule );
            // Skipping cannot fail as recoverSet must contain end of file (EOF)
            skipTo( recoverSet );
        }
        debugLevel--;  /* Decrease debugging level at end of rule */
        debugMessage( "End parse " + rule );
    }
    /** Output debugging message if debug turned on */
    private void debugMessage( String msg ) {
        if( debugParse ) {
            /* Indent message by the level of nesting of parsing rules */
            String indent = "";
            for( int i = 1; i <= debugLevel; i++ ) {
                indent += " ";
            }
            System.out.println( indent + msg );
        }
    }
    /** Error message handle for parsing errors */
    private void parseError( String msg ) {
        debugMessage( msg );
        error( msg );
    }
   
    /**************************** Parsing Methods ***************************/

    /** RULE: Program -> InputVariables Statement END_OF_FILE */
    private Program parseProgram( TokenSet recoverSet ) {
        if( !beginRule( "Program", Token.KW_INPUTS, recoverSet ) ) {
            return null;
        }
        SortedSet<String> inputs = parseInputVariables(
                recoverSet.union( STATEMENT_START_SET ) );
        Statement statement = parseStatement( recoverSet );
        /* We can't use match( Token.END_OF_FILE ) because there is 
         * nothing following end of file */
        endRule( "Program", recoverSet );
        return new Program( inputs, statement );
    }
    /** RULE: InputVariables -> KW_INPUTS Variables SEMICOLON */
    private SortedSet<String> parseInputVariables( TokenSet recoverSet ) {
        SortedSet<String> inputs = new TreeSet<String>();
        if( !beginRule( "InputVariables", Token.KW_INPUTS, recoverSet ) ) {
            return inputs;
        }
        match( Token.KW_INPUTS ); // can't fail
        inputs = parseVariables( recoverSet.union(Token.SEMICOLON) );
        match( Token.SEMICOLON, recoverSet );
        endRule( "InputVariables", recoverSet );
        return inputs;
    }
    /** RULE: Variables -> IDENTIFIER { COMMA IDENTIFIER } */
    private SortedSet<String> parseVariables( TokenSet recoverSet ) {
        SortedSet<String> vars = new TreeSet<String>();
        if( !beginRule( "Variables", Token.IDENTIFIER, recoverSet ) ) {
            return vars;
        }
        vars.add( token.getName() );
        match( Token.IDENTIFIER ); //can't fail
        while( token.isMatch( Token.COMMA ) ) {
            match( Token.COMMA );   // can't fail
            if( token.isMatch( Token.IDENTIFIER ) ) {
                vars.add( token.getName() );
            }
            match( Token.IDENTIFIER, recoverSet.union( Token.COMMA ) );
        }
        endRule( "Variables", recoverSet );
        return vars;
    }
    /** RULE: Statement -> NullStatement | Assignment | 
     *                     CompoundStatement | Select | Repeat
     */
    private Statement parseStatement( TokenSet recoverSet ) {
        if( !beginRule( "Statement", STATEMENT_START_SET, recoverSet ) ) {
            return new Primitive.ErrorStatement( token.getPosn() );
        }
        Statement statement;
        switch ( token.getKind() ) {
        case KW_NULL:
            statement = parseNullStatement( recoverSet );
            break;
        case IDENTIFIER:
            statement = parseAssignment( recoverSet );
            break;
        case LCURLY:
            statement = parseCompoundStatement( recoverSet );
            break;
        case KW_SELECT:
            statement = parseSelect( recoverSet );
            break;
        case KW_REPEAT:
            statement = parseRepeat( recoverSet );
            break;
        default:
            /** Should never get here */
            statement = null;
            fatal( "Fatal error in parseStatement" );
            break;
        }
        endRule( "Statement", recoverSet );
        return statement;
    }
    /** RULE: NullStatement -> KW_NULL SEMICOLON */
    private Statement parseNullStatement( TokenSet recoverSet ) {
        beginRule( "NullStatement", Token.KW_NULL ); // can't fail
        Position pos = token.getPosn();
        match( Token.KW_NULL ); // can't fail
        match( Token.SEMICOLON, recoverSet );
        endRule( "NullStatement", recoverSet );
        return new Primitive.NullStatement( pos );
    }
    /** RULE: Assignment -> IDENTIFIER ASSIGN Expression SEMICOLON */
    private Statement parseAssignment( TokenSet recoverSet ) {
        beginRule( "Assignment", Token.IDENTIFIER ); // can't fail
        String varName = token.getName();;
        Position pos = token.getPosn();
        match( Token.IDENTIFIER ); // can't fail
        match( Token.ASSIGN, EXPRESSION_START_SET );
        DependSet depends = parseExpression( 
                recoverSet.union(Token.SEMICOLON) );
        match( Token.SEMICOLON, recoverSet );
        endRule( "Assignment", recoverSet );
        return new Primitive.Assignment( pos, varName, depends );
    }
    /** RULE: Expression -> NUMBER | Variables */
    private DependSet parseExpression( TokenSet recoverSet ) {
        if( !beginRule( "Expression", EXPRESSION_START_SET, recoverSet ) ) {
            return new DependSet();
        }
        DependSet depends;
        switch ( token.getKind() ) {
        case NUMBER:
            // No dependencies
            match( Token.NUMBER );
            depends = new DependSet();
            break;
        case IDENTIFIER:
            SortedSet<String> variables = parseVariables( recoverSet );
            depends = new DependSet( variables );
            break;
        default:
            depends = null;
            fatal( "fatal error parseExpression" );
            break;
        }
        endRule( "Expression", recoverSet );
        return depends;
    }
    /** Rule: CompoundStatement -> LCURLY Statement { Statement } RCURLY  */
    private Statement parseCompoundStatement( TokenSet recoverSet ) {
        beginRule( "Compound Statement", Token.LCURLY ); // can't fail
        Position pos = token.getPosn();
        match( Token.LCURLY );  // can't fail
        List<Statement> statements = new LinkedList<Statement>();
        statements.add( parseStatement( 
            recoverSet.union( STATEMENT_START_SET.union(Token.RCURLY) ) ) );
        while( !token.isMatch( Token.RCURLY ) ) {
            statements.add( parseStatement(
                    recoverSet.union( 
                            STATEMENT_START_SET.union( Token.RCURLY) ) ) );
        }
        match( Token.RCURLY, recoverSet );
        endRule( "Compound Statement", recoverSet );
        return new Statement.Compound( pos, statements );
    }
    /** RULE: Select -> KW_SELECT LCURLY Statement { ALT Statement } RCURLY */
    private Statement parseSelect( TokenSet recoverSet ) {
        beginRule( "Select", Token.KW_SELECT );  // can't fail
        Position pos = token.getPosn();
        match( Token.KW_SELECT );  // can't fail
        Set<Statement> statements = new HashSet<Statement>();
        match( Token.LCURLY, STATEMENT_START_SET );
        statements.add( parseStatement( 
                recoverSet.union( Token.ALT, Token.RCURLY ) ) );
        while( token.isMatch( Token.ALT ) ) {
            match( Token.ALT );  // can't fail
            statements.add( parseStatement( 
                    recoverSet.union( Token.ALT, Token.RCURLY ) ) );
        }
        match( Token.RCURLY, recoverSet );
        endRule( "Select", recoverSet );
        return new Statement.Select( pos, statements );
    }
    /** Rule: Repeat -> KW_REPEAT Statement */
    private Statement parseRepeat( TokenSet recoverSet ) {
        beginRule( "Repeat", Token.KW_REPEAT ); // can't fail
        Position pos = token.getPosn();
        match( Token.KW_REPEAT );  // can't fail
        Statement statement = parseStatement( recoverSet );
        endRule( "Repeat", recoverSet );
        return new Statement.Repeat( pos, statement );
    }

/*********************** Private convenience Methods ************************/
    /** Assert that condition is true. Otherwise throw an error which should
     * abort the parser immediately
     */
    private void parseAssert( boolean condition, String m ) {
        if( !condition ) fatal( "Assertion failed! " + m );
    }
    /** Signal an error at the given position */
    private void error( String m, Position pos ) {
        errors.errorMessage( m, Severity.ERROR, pos );
    }
    /** Signal an error at the current token position */
    private void error( String m ) {
        error( m, token.getPosn() );
    }
    /** Signal a fatal error at the given position */
    private void fatal( String m, Position pos ) {
        errors.errorMessage( m, Severity.FATAL, pos );
    }
    /** Signal a fatal error at the current token position */
    private void fatal( String m ) {
        fatal( m, token.getPosn() );
    }
}
